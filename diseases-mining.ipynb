{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diseases Mining from Pubtator Central"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preqrequisites Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import calendar\n",
    "import time\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mining Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ncbi.nlm.nih.gov/research/pubtator-api/publications/export/biocxml?pmids={}\"\n",
    "\n",
    "pubs_df = pd.read_csv(\"./data/1676879038-pubs-breast-cancer-4860.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_str = \"Logs: {}\"\n",
    "\n",
    "def get_disease_from_pubs(row):\n",
    "    # print(logs_str.format(\"Getting disease from pub: {}\".format(row['PMID'])))\n",
    "\n",
    "    disease = np.array([])\n",
    "\n",
    "    metadata_url = url.format(row['PMID'])\n",
    "    metadata_response = requests.get(metadata_url)\n",
    "\n",
    "    metadata_soup = BeautifulSoup(metadata_response.content, 'lxml')\n",
    "    disease_sections = metadata_soup.find_all('infon', {'key': 'type'})\n",
    "    for disease_section in disease_sections:\n",
    "        if(disease_section.get_text().strip().lower() == 'disease'):\n",
    "            text = disease_section.parent.find('text').get_text().strip()\n",
    "            new_disease = np.array([row['PMID'], text])\n",
    "            disease = np.append(disease, new_disease)\n",
    "\n",
    "    # print(logs_str.format(\"Found: {} diseases\".format(disease.size)))\n",
    "\n",
    "    return disease\n",
    "\n",
    "def get_disease(df, limit=0):\n",
    "    print(logs_str.format(\"ðŸ”¨ Getting disease from {} publications\".format(df.shape[0])))\n",
    "    disease = np.array([])\n",
    "\n",
    "    pqbar = tqdm(description=\"Processing\", total=df.shape[0])\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if(limit > 0 and index >= limit):\n",
    "            break\n",
    "\n",
    "        # print(logs_str.format(\"Iteration number: {}\".format(index)))\n",
    "        \n",
    "        try:\n",
    "            new_disease = get_disease_from_pubs(row)\n",
    "            disease = np.append(disease, new_disease)\n",
    "        except Exception as e:\n",
    "            print(logs_str.format(\"Error: {}\".format(e)))\n",
    "            continue\n",
    "        finally:\n",
    "            pqbar.update(1)\n",
    "    \n",
    "    pqbar.close()\n",
    "    print(\"-\" * 30)\n",
    "    print(logs_str.format(\"ðŸŒŸ Job done!\"))\n",
    "    print(\"-\" * 30)\n",
    "    print(logs_str.format(\"ðŸ“Š Found {} diseases\".format(disease.size)))\n",
    "    \n",
    "    return disease\n",
    "\n",
    "def transorm_to_df(dis, columns):\n",
    "    df = pd.DataFrame(dis.reshape(-1, 2), columns=columns)\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs: ðŸ”¨ Getting disease from 4860 publications\n",
      "Logs: Iteration number: 0\n",
      "Logs: Getting disease from pub: 36800640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\Anaconda3\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs: Found: 0 diseases\n",
      "Logs: Iteration number: 1\n",
      "Logs: Getting disease from pub: 36800620\n",
      "Logs: Found: 0 diseases\n",
      "Logs: Iteration number: 2\n",
      "Logs: Getting disease from pub: 36800575\n",
      "Logs: Found: 0 diseases\n",
      "--------------------------------------------------\n",
      "Logs: ðŸŒŸ Job done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PMID, Disease]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diseases = get_disease(pubs_df)\n",
    "diseases_df = transorm_to_df(diseases, ['PMID', 'Disease'])\n",
    "\n",
    "diseases_df.dropna(inplace=True) # Remove NaN\n",
    "diseases_df[\"Disease\"] = diseases_df[\"Disease\"].astype(str).str.lower() # Lowercase\n",
    "diseases_df = diseases_df.drop_duplicates() # Remove duplicates\n",
    "\n",
    "diseases_df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./data/\"\n",
    "ts = calendar.timegm(time.gmtime())\n",
    "num_dis = diseases_df.shape[0]\n",
    "file_name = \"{}-diseases-{}.csv\".format(ts, num_dis)\n",
    "\n",
    "diseases_df.to_csv(file_path+file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af2924f10f5eb76fd65ccea448a69e80be7838e947e8a1ae982ab7073141c8a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
